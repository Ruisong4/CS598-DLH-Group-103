{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmHMfxLu293l"
      },
      "source": [
        "# Loading the library we need and setup GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYn5c50v0cB1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "from gensim.models import KeyedVectors\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler, random_split, Dataset\n",
        "from sklearn.model_selection import KFold\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import nltk\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q1VKrN9BNVm"
      },
      "source": [
        "Setup GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-WaMX-HBMsE"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj_YOSA-7uT2"
      },
      "source": [
        "Setup the working dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIurNu8l7zbt"
      },
      "outputs": [],
      "source": [
        "#depending on your system and computer\n",
        "drive.mount('/content/drive/')\n",
        "os.chdir(\"/content/drive/My Drive/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Pre-processing"
      ],
      "metadata": {
        "id": "Q0Tt79Hy24pj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8qhV0Qvbd2b"
      },
      "source": [
        "Load word2vec from file, place them in a wrapper class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDBZY448bjeF"
      },
      "outputs": [],
      "source": [
        "# load the binary file\n",
        "model = KeyedVectors.load_word2vec_format(\"PubMed-w2v.bin\", binary=True)\n",
        "\n",
        "# create a util class to handle words not in model\n",
        "class W2V:\n",
        "  def __init__(self, model=None):\n",
        "    self.w2v = model\n",
        "    self.embedding_size = self.w2v.vector_size\n",
        "    self.unknow_words = dict()\n",
        "    # map all unknow words to unk token\n",
        "    self.unk = np.random.uniform(-1, 1, (self.embedding_size,))\n",
        "  def __getitem__(self, key):\n",
        "    if key in self.w2v:\n",
        "      return self.w2v[key]\n",
        "    return self.unk\n",
        "    if key not in self.unknow_words:\n",
        "      self.unknow_words[key] = np.random.uniform(-1, 1, (self.embedding_size,))\n",
        "    return self.unknow_words.get(key)\n",
        "\n",
        "w2v = W2V(model)\n",
        "print(\"Word2Vec Model Loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buIjqCAii2aa"
      },
      "source": [
        "Load pre-processed data from file, output of the pre-processing script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn5-kY-acGEQ"
      },
      "outputs": [],
      "source": [
        "x_general = []\n",
        "x_thirty_days = []\n",
        "y_general = []\n",
        "y_thirty_days = []\n",
        "\n",
        "removed_index1 = set()\n",
        "removed_index2 = set()\n",
        "\n",
        "#load the general task's discharge summaries\n",
        "count = 0\n",
        "with open('x.txt') as f:\n",
        "    line = f.readline()\n",
        "    while line:\n",
        "      count += 1\n",
        "      # exclude short summary\n",
        "      if len(line) > 250:\n",
        "        x_general.append(line)\n",
        "      else:\n",
        "        removed_index1.add(count)\n",
        "      line = f.readline()\n",
        "\n",
        "# load thirty day discharge summaries\n",
        "count = 0\n",
        "with open('x_30.txt') as f:\n",
        "    line = f.readline()\n",
        "    while line:\n",
        "      count += 1\n",
        "      # exclude short summary\n",
        "      if len(line) > 250:\n",
        "        x_thirty_days.append(line)\n",
        "      else:\n",
        "        removed_index2.add(count)\n",
        "      line = f.readline()\n",
        "\n",
        "# Load general labels\n",
        "count = 0\n",
        "with open('y.txt') as f:\n",
        "    line = f.readline()\n",
        "    while line:\n",
        "      count += 1\n",
        "      if count not in removed_index1:\n",
        "        y_general.append(int(line))\n",
        "      line = f.readline()\n",
        "\n",
        "# Load thirty day labels\n",
        "count = 0\n",
        "with open('y_30.txt') as f:\n",
        "    line = f.readline()\n",
        "    while line:\n",
        "      count += 1\n",
        "      if count not in removed_index2:\n",
        "        y_thirty_days.append(int(line))\n",
        "      line = f.readline()\n",
        "\n",
        "y_general = np.array(y_general)\n",
        "y_thirty_days = np.array(y_thirty_days)\n",
        "\n",
        "# sanity check\n",
        "assert len(x_general) == len(y_general)\n",
        "assert len(x_thirty_days) == len(y_thirty_days)\n",
        "assert y_general.max() == 1 and y_general.min() == 0\n",
        "assert y_thirty_days.max() == 1 and y_thirty_days.min() == 0\n",
        "print(\"Data File Loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_H2kKaFOVOF"
      },
      "source": [
        "tokenize the discharge note into words and calculating the max document length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J0Kq6lHObpi",
        "outputId": "5b961155-4bd4-4f70-9194-4af9c31fa578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "removed -6065534 words\n",
            "removed -1212059 words\n",
            "Finish tokenizing all words\n",
            "In general dataset the max word count: 3939 min count: 28 avg: 1111.7796940194714\n",
            "In 30-days dataset the max word count: 3381 min count: 68 avg: 1137.3510560815732\n"
          ]
        }
      ],
      "source": [
        "x_general_tokenized = []\n",
        "x_thirty_days_tokenized = []\n",
        "x_general_max_words = 0\n",
        "x_thirty_days_max_words = 0\n",
        "x_general_min_words = np.inf\n",
        "x_thirty_days_min_words = np.inf\n",
        "x_general_avg_words = 0\n",
        "x_thirty_days_avg_words = 0\n",
        "\n",
        "number_removed = 0\n",
        "for note in x_general:\n",
        "  words = nltk.word_tokenize(note)\n",
        "  size = len(words)\n",
        "  # remove all numbers\n",
        "  words = [word for word in words if word.isalnum() and not(word.isnumeric())]\n",
        "  number_removed += len(words) - size\n",
        "  x_general_tokenized.append(words)\n",
        "  x_general_max_words = max(x_general_max_words, len(words))\n",
        "  x_general_min_words = min(x_general_min_words, len(words))\n",
        "  x_general_avg_words += len(words)\n",
        "x_general_avg_words /= len(x_general_tokenized)\n",
        "\n",
        "print(\"removed\", number_removed, \"words\")\n",
        "\n",
        "number_removed = 0\n",
        "for note in x_thirty_days:\n",
        "  words = nltk.word_tokenize(note)\n",
        "  size = len(words)\n",
        "  words = [word for word in words if word.isalnum() and not(word.isnumeric())]\n",
        "  number_removed += len(words) - size\n",
        "  x_thirty_days_tokenized.append(words)\n",
        "  x_thirty_days_max_words = max(x_thirty_days_max_words, len(words))\n",
        "  x_thirty_days_min_words = min(x_thirty_days_min_words, len(words))\n",
        "  x_thirty_days_avg_words += len(words)\n",
        "x_thirty_days_avg_words /= len(x_thirty_days_tokenized)\n",
        "print(\"removed\", number_removed, \"words\")\n",
        "\n",
        "print(\"Finish tokenizing all words\")\n",
        "print(\"In general dataset the max word count:\", x_general_max_words, \"min count:\", x_general_min_words, \"avg:\", x_general_avg_words)\n",
        "print(\"In 30-days dataset the max word count:\", x_thirty_days_max_words, \"min count:\", x_thirty_days_min_words, \"avg:\", x_thirty_days_avg_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the Model and Loader"
      ],
      "metadata": {
        "id": "8xxXNFhd31vN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUmJqooEnZO4"
      },
      "source": [
        "1.   Create DataSet to hold the data\n",
        "2.   Generarte train and val dataset (90% train 10% val, accodring to the paper)\n",
        "3.   Creating DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeLdQFq3n_8l"
      },
      "outputs": [],
      "source": [
        "class ReadmissionDataSet(Dataset):\n",
        "  def __init__(self, notes, labels, w2v, max_len):\n",
        "    self.x = notes\n",
        "    self.y = labels\n",
        "    self.max_len = max_len\n",
        "    self.w2v = w2v\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    note = np.array([self.w2v[w] for w in self.x[index]], dtype=np.float32)\n",
        "    padded = note\n",
        "    if (len(note) < self.max_len):\n",
        "      pad = np.zeros((self.max_len - len(note), w2v.embedding_size,), dtype=np.float32)\n",
        "      padded = np.concatenate([padded, pad])\n",
        "    return padded, self.y[index]\n",
        "\n",
        "general_data_set = ReadmissionDataSet(x_general_tokenized, y_general, w2v, x_general_max_words)\n",
        "thirty_days_data_set = ReadmissionDataSet(x_thirty_days_tokenized, y_thirty_days, w2v, x_thirty_days_max_words)\n",
        "\n",
        "print(len(general_data_set))\n",
        "print(len(thirty_days_data_set))\n",
        "\n",
        "general_training_size = int(0.9 * len(general_data_set))\n",
        "thirty_days_training_size = int(0.9 * len(thirty_days_data_set))\n",
        "\n",
        "general_test_size = len(general_data_set) - general_training_size\n",
        "thirty_days_test_size = len(thirty_days_data_set) - thirty_days_training_size\n",
        "\n",
        "general_train_dataset, general_test_dataset = random_split(general_data_set, [general_training_size, general_test_size])\n",
        "thirty_days_train_dataset, thirty_days_test_dataset = random_split(thirty_days_data_set, [thirty_days_training_size, thirty_days_test_size])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sur6iwuBq94C"
      },
      "source": [
        "Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9y_EFQx0q8s1"
      },
      "outputs": [],
      "source": [
        "class ReadmissionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ReadmissionModel, self).__init__()\n",
        "    # Three conv layers to extract feature of length 1, 2 and 3\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(1, 200))\n",
        "    self.conv2 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(2, 200))\n",
        "    self.conv3 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(3, 200)) \n",
        "    # dropout prevent overfitting\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "    # linear layer make final prediction\n",
        "    self.linear1 = nn.Linear(64 * 3, 96)\n",
        "    self.linear2 = nn.Linear(96, 2)\n",
        "    \n",
        "  def forward(self, x):\n",
        "\n",
        "    unsqueezed = torch.unsqueeze(x, 1)\n",
        "\n",
        "    con1_out = self.conv1(unsqueezed)\n",
        "    con1_out = torch.squeeze(con1_out, dim=3)\n",
        "    con1_out = F.relu(con1_out)\n",
        "    con1_out = F.max_pool1d(con1_out, kernel_size=con1_out.shape[2])\n",
        "    con1_out = torch.squeeze(con1_out, dim=2)\n",
        "\n",
        "    con2_out = self.conv2(unsqueezed)\n",
        "    con2_out = torch.squeeze(con2_out, dim=3)\n",
        "    con2_out = F.relu(con2_out)\n",
        "    con2_out = F.max_pool1d(con2_out, kernel_size=con2_out.shape[2])\n",
        "    con2_out = torch.squeeze(con2_out, dim=2)\n",
        "\n",
        "    con3_out = self.conv3(unsqueezed)\n",
        "    con3_out = torch.squeeze(con3_out, dim=3)\n",
        "    con3_out = F.relu(con3_out)\n",
        "    con3_out = F.max_pool1d(con3_out, kernel_size=con3_out.shape[2])\n",
        "    con3_out = torch.squeeze(con3_out, dim=2)\n",
        "\n",
        "    # Combine the result of three conv layers\n",
        "    out = torch.cat((con1_out, con2_out, con3_out), dim=1)\n",
        "    out = self.dropout(out)\n",
        "    out = self.linear1(out)\n",
        "    out = self.linear2(out)\n",
        "\n",
        "    #print(\"output size:\",torch.squeeze(self.linear(out)).shape)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train And Evaluate Model"
      ],
      "metadata": {
        "id": "zjmEO2t53-7i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wys7ZRtrjO7x"
      },
      "source": [
        "helper function to calculate accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_g_lFNFZVeu"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, labels):\n",
        "    preds = output.argmax(dim=1)\n",
        "    correct = (preds == labels).sum().float()\n",
        "    acc = correct / len(labels)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OsVTipu9UFa"
      },
      "source": [
        "Helper function to train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jKLeojM9TSW"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, n_epoch, optimizer, criterion, device):\n",
        "  model.train()\n",
        "  m = nn.LogSoftmax(dim=1)\n",
        "  for epoch in range(n_epoch):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    for data, target in train_loader:\n",
        "      data = data.to(device)\n",
        "      target = target.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      y_hat = model(data)\n",
        "      acc = accuracy(y_hat, target)\n",
        "\n",
        "      loss = criterion(y_hat, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "    print(f\"Epoch {epoch}: loss: {epoch_loss / len(train_loader)} acc: {100*epoch_acc / len(train_loader)}\")\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV2rw9VHCZ4q"
      },
      "source": [
        "Helper function to test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sBvzJTTCcoO"
      },
      "outputs": [],
      "source": [
        "def test_model(model, test_loader):\n",
        "  model.eval()\n",
        "  Y_pred = []\n",
        "  Y_test = []\n",
        "\n",
        "  for data, target in test_loader:\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "    Y_test.extend(target.tolist())\n",
        "    y_hat = model(data)\n",
        "    y_hat = y_hat.argmax(dim=1)\n",
        "    Y_pred.extend(y_hat.tolist())\n",
        "\n",
        "  Y_test = np.array(Y_test)\n",
        "\n",
        "  return Y_pred, Y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua0FA-6ZW1Ag"
      },
      "source": [
        "define collate function, mainly for type conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNlfKmHHW0s6"
      },
      "outputs": [],
      "source": [
        "def collate_fn(data):\n",
        "  return torch.cat([torch.unsqueeze(torch.from_numpy(x[0]), 0) for x in data], dim=0).float(), torch.tensor([x[1] for x in data], dtype=torch.int64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyWV6dFm5big"
      },
      "source": [
        "10-fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opqBPbAFAiWt"
      },
      "outputs": [],
      "source": [
        "def cross_validate(model, dataset, n_splits, batch_size, n_epoch, optimizer, criterion, device):\n",
        "\n",
        "  kfold = KFold(n_splits=n_splits, shuffle=True, random_state=598)\n",
        "\n",
        "  model_performance = []\n",
        "\n",
        "  for fold, (train_idx, test_idx) in enumerate(kfold.split(dataset)):\n",
        "    print(\"Fold\", fold, \"begins\")\n",
        "    train_subsampler = SubsetRandomSampler(train_idx)\n",
        "    test_subsampler = SubsetRandomSampler(test_idx)\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_subsampler, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_subsampler, collate_fn=collate_fn)\n",
        "    \n",
        "    # clear model weight for next fold\n",
        "    count = 0\n",
        "\n",
        "    for layer in model.children():\n",
        "      if hasattr(layer, \"reset_parameters\"):\n",
        "        count += 1\n",
        "        layer.reset_parameters()\n",
        "    print(\"resetting weight in\", count, \"layers\")\n",
        "\n",
        "    train_model(model, train_loader, n_epoch, optimizer, criterion, device)\n",
        "    \n",
        "    # store the model weight to file so we can choose the best one\n",
        "    torch.save(model.state_dict(), \"fold-\" + str(fold) + \".model\")\n",
        "\n",
        "    Y_pred, Y_test = test_model(model, test_loader)\n",
        "    acc = accuracy_score(Y_test, Y_pred)\n",
        "    p, r, f, _ = precision_recall_fscore_support(Y_test, Y_pred, average='binary')\n",
        "    print(\"Fold\", fold, \"results: \", \"percision:\", p, \"recall\", r, \"f1\", f, \"acc\", acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZrWDTx9FsmM"
      },
      "source": [
        "Create a new model for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN08VOLsPOQt"
      },
      "outputs": [],
      "source": [
        "model = ReadmissionModel()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "model = model.to(device)\n",
        "print(model)\n",
        "criterion = criterion.to(device)\n",
        "cross_validate(model, general_train_dataset, 10, 128, 15, optimizer, criterion, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6APDYaXci7K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0fad765-3b12-4cec-aca3-ba5e77737c8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95714"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "model = ReadmissionModel()\n",
        "sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper function to evaluate the model"
      ],
      "metadata": {
        "id": "AHfRCsEJ4ii7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wU94ozqHfJXl"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataset, device, weight_file_names):\n",
        "  test_loader = DataLoader(dataset, batch_size=32, collate_fn=collate_fn)\n",
        "  for weight_file in weight_file_names:\n",
        "    #claer weight before evaluate the next model\n",
        "    count = 0\n",
        "    for layer in model.children():\n",
        "      if hasattr(layer, \"reset_parameters\"):\n",
        "        count += 1\n",
        "        layer.reset_parameters()\n",
        "    print(\"resetting weight in\", count, \"layers\")\n",
        "    model.load_state_dict(torch.load(weight_file))\n",
        "    Y_pred, Y_test = test_model(model, test_loader)\n",
        "    acc = accuracy_score(Y_test, Y_pred)\n",
        "    p, r, f, _ = precision_recall_fscore_support(Y_test, Y_pred, average='binary')\n",
        "    print(\"model\", weight_file, \"results: \", \"percision:\", p, \"recall\", r, \"f1\", f, \"acc\", acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load weights file and run the test"
      ],
      "metadata": {
        "id": "3K9uUV4a4pWW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjeUO_Flgimy"
      },
      "outputs": [],
      "source": [
        "files = [\"fold-\" + str(i) + \".model\" for i in range(1, 10)]\n",
        "model.to(device)\n",
        "evaluate_model(model, general_test_dataset, device, files)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "CS598 Final Project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}