{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from gensim.parsing.preprocessing import remove_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify MIMIC-iii data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'mimic-iii-clinical-database-1.4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in admission info, diagnoses with ICD9 codes, and clinical notes CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions = pd.read_csv(f'{DATA_FOLDER}/ADMISSIONS.csv')\n",
    "diagnoses_ICD = pd.read_csv(f'{DATA_FOLDER}/DIAGNOSES_ICD.csv')\n",
    "note_events = pd.read_csv(f'{DATA_FOLDER}/NOTEEVENTS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop \"ROW_ID\" column for each CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addmissions = admissions.drop(columns=[\"ROW_ID\"])\n",
    "diagnoses_ICD = diagnoses_ICD.drop(columns=[\"ROW_ID\"])\n",
    "note_events = note_events.drop(columns=[\"ROW_ID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DROP NAN rows in clinical notes, and change dtype of admission ID from float to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_events = note_events.dropna(subset=['SUBJECT_ID', 'HADM_ID', 'TEXT'])\n",
    "note_events['HADM_ID'] = note_events['HADM_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For admissions that have mutiple discharge summary notes, only keep the longest discharge summary notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_longest_note(row):\n",
    "    return [x for x in row.tolist() if len(x) == max([len(x) for x in row.tolist()])][0]\n",
    "\n",
    "note_events = note_events.groupby('HADM_ID')['TEXT'].apply(keep_longest_note).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge admission info and diagnoes ICD9 codes based on the unique patient ID and admission id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions_ICD = pd.merge(admissions, diagnoses_ICD, on=[\"HADM_ID\", \"SUBJECT_ID\"])\n",
    "admissions_ICD = admissions_ICD.drop(columns=[\"ROW_ID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify ICD9 codes related to heart failure, and filter admissions to keep only heart failure admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_ICD = ['39891', '40201', '40211', '40291',\n",
    "          '40401', '40403', '40411', '40413', \n",
    "          '40491', '40493', '4280', '4281',\n",
    "          '42820', '42821', '42822', '42823', \n",
    "          '42830', '42831', '42832', '42833',\n",
    "          '42840', '42841', '42842', '42843', '4289']\n",
    "hf_admissions = admissions_ICD[admissions_ICD['ICD9_CODE'].isin(hf_ICD)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of admission ID that has discharge summary note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_admission_with_note = note_events['HADM_ID'].astype(int).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter admissions to keep only admissions with a discharge summary note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_admissions = hf_admissions[hf_admissions['HADM_ID'].isin(hf_admission_with_note)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge admission with notes, and keep only 4 useful columns: patient ID, admission ID, admission time, discharge summary notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = pd.merge(hf_admissions, note_events, on=['HADM_ID'])\n",
    "cleaned = cleaned[['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'TEXT']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicate rows with same admission ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = cleaned.drop_duplicates('HADM_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Python Dict to map from patient ID to admission ID, admission ID to admission time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_to_admission = {}\n",
    "admission_to_time = {}\n",
    "\n",
    "patients = cleaned['SUBJECT_ID'].to_list()\n",
    "admissions = cleaned['HADM_ID'].to_list()\n",
    "time = cleaned['ADMITTIME'].to_list()\n",
    "\n",
    "for patient, admission, time in zip(patients, admissions, time):\n",
    "    if patient not in patient_to_admission:\n",
    "        patient_to_admission[patient] = []\n",
    "    patient_to_admission[patient].append(admission)\n",
    "    parsed_time = time[:10].split('-')\n",
    "    admission_to_time[admission] = date(int(parsed_time[0]), int(parsed_time[1]), int(parsed_time[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Dataframe to Python Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cleaned.set_index('HADM_ID').to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign 30 days readmission label and general readimssion label based on admission time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for admission, info in data.items():\n",
    "    patient = info['SUBJECT_ID']\n",
    "    info['30_DAY_READMISSION'] = 0\n",
    "    info['GENERAL_READMISSION'] = 0\n",
    "    for other_admission in patient_to_admission[patient]:\n",
    "        time_diff = (admission_to_time[other_admission] - admission_to_time[admission]).days\n",
    "        if time_diff > 0:\n",
    "            info['GENERAL_READMISSION'] = 1\n",
    "        if 30 >= time_diff > 0:\n",
    "            info['30_DAY_READMISSION'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Python Dict to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_dict(data, orient='index').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={\"index\": \"HADM_ID\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract postive examples and sample same number of negative examples from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postive = data[data['GENERAL_READMISSION'] == 1]\n",
    "postive_30 = data[data['30_DAY_READMISSION'] == 1]\n",
    "negative = data[data['GENERAL_READMISSION'] == 0].sample(len(postive))\n",
    "negative_30 = data[data['30_DAY_READMISSION'] == 0].sample(len(postive_30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat postive and negative examples to form dataset for general readmission and 30 days readmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([postive, negative])\n",
    "data_30 = pd.concat([postive_30, negative_30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Dataframe to Python List and get text and labels for general readmission and 30 days readmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['TEXT'].to_list()\n",
    "y = data['GENERAL_READMISSION'].to_list()\n",
    "x_30 = data_30['TEXT'].to_list()\n",
    "y_30 = data_30['30_DAY_READMISSION'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stop words from text using Genism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [remove_stopwords(text) for text in x]\n",
    "x_30 = [remove_stopwords(text) for text in x_30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the text and labels to txt file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CS598_DATA/x.txt', 'w') as fd:\n",
    "    for data in x:\n",
    "        data = str(data) + '\\n'\n",
    "        fd.writelines(data)\n",
    "\n",
    "with open('CS598_DATA/x_30.txt', 'w') as fd:\n",
    "    for data in x_30:\n",
    "        data = str(data) + '\\n'\n",
    "        fd.writelines(data)\n",
    "\n",
    "with open('CS598_DATA/y.txt', 'w') as fd:\n",
    "    for data in y:\n",
    "        data = str(data) + '\\n'\n",
    "        fd.writelines(data)\n",
    "\n",
    "with open('CS598_DATA/y_30.txt', 'w') as fd:\n",
    "    for data in y_30:\n",
    "        data = str(data) + '\\n'\n",
    "        fd.writelines(data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
